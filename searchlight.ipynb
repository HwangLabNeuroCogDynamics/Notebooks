{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searchlight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works\n",
    "Takes niftii images and applies a mask to generate spheres of inputed radius. Applies a function to each sphere and returns list of all spheres' results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searchlight class\n",
    "```\n",
    "Implement search_light analysis using an arbitrary type of classifier.\n",
    "    Parameters\n",
    "    -----------\n",
    "    mask_img : Niimg-like object\n",
    "        See http://nilearn.github.io/manipulating_images/input_output.html\n",
    "        boolean image giving location of voxels containing usable signals.\n",
    "    func : function \n",
    "        to apply to each sphere\n",
    "    args : list\n",
    "        additional arguments for func\n",
    "    process_mask_img : Niimg-like object, optional\n",
    "        See http://nilearn.github.io/manipulating_images/input_output.html\n",
    "        boolean image giving voxels on which searchlight should be\n",
    "        computed.\n",
    "    radius : float, optional\n",
    "        radius of the searchlight ball, in millimeters. Defaults to 2.\n",
    "    estimator : 'svr', 'svc', or an estimator object implementing 'fit'\n",
    "        The object to use to fit the data\n",
    "    %(n_jobs)s\n",
    "    scoring : string or callable, optional\n",
    "        The scoring strategy to use. See the scikit-learn documentation\n",
    "        If callable, takes as arguments the fitted estimator, the\n",
    "        test data (X_test) and the test target (y_test) if y is\n",
    "        not None.\n",
    "    cv : cross-validation generator, optional\n",
    "        A cross-validation generator. If None, a 3-fold cross\n",
    "        validation is used or 3-fold stratified cross-validation\n",
    "        when y is supplied.\n",
    "    %(verbose0)s\n",
    "    Notes\n",
    "    ------\n",
    "    The searchlight [Kriegeskorte 06] is a widely used approach for the\n",
    "    study of the fine-grained patterns of information in fMRI analysis.\n",
    "    Its principle is relatively simple: a small group of neighboring\n",
    "    features is extracted from the data, and the prediction function is\n",
    "    instantiated on these features only. The resulting prediction\n",
    "    accuracy is thus associated with all the features within the group,\n",
    "    or only with the feature on the center. This yields a map of local\n",
    "    fine-grained information, that can be used for assessing hypothesis\n",
    "    on the local spatial layout of the neural code under investigation.\n",
    "    Nikolaus Kriegeskorte, Rainer Goebel & Peter Bandettini.\n",
    "    Information-based functional brain mapping.\n",
    "    Proceedings of the National Academy of Sciences\n",
    "    of the United States of America,\n",
    "    vol. 103, no. 10, pages 3863-3868, March 2006\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First two arguments must be X (spheres holding data) and the indices of the voxels in the sphere (use to work with other data not in sphere form, such as a noise regression). The rest are the additional arguments you pass to the searchlight class.\n",
    "\n",
    "Example:  \n",
    "```\n",
    "def decode_cues(X, sphere_voxel_idxs, y, classifier, cues, runs, tent_length=9):\n",
    "    ...\n",
    "\n",
    "\n",
    "sl_obj = searchlight.SearchLight(frontal_mask, decode_cues, [subject_lss_data.trial_df.Cue.to_numpy(), clf, CUES, subject_lss_data.trial_df.Run.to_numpy()], verbose=1, radius=10.0, n_jobs=4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thalhi.decoding import SubjectLssTentData, decode_cues\n",
    "from thalpy.decoding import searchlight\n",
    "import pickle\n",
    "from thalpy import base\n",
    "\n",
    "THAL_HI_DIR = \"/mnt/nfs/lss/lss_kahwang_hpc/data/ThalHi/\"\n",
    "CUES = [\"dcb\", \"fcb\", \"dpb\", \"fpb\", \"dcr\", \"fcr\", \"dpr\", \"fpr\"]\n",
    "\n",
    "dir_tree = base.DirectoryTree(THAL_HI_DIR)\n",
    "subjects = base.get_subjects(dir_tree.deconvolve_dir, dir_tree)\n",
    "\n",
    "subject = next(sub for sub in subjects if sub.name == \"10002\")\n",
    "\n",
    "os.chdir(subject.deconvolve_dir)\n",
    "subject_lss_data = SubjectLssTentData.load(\"LSS_TENT.p\")\n",
    "subject_lss_data.remove_nan_trials()\n",
    "\n",
    "clf = OneVsRestClassifier(LinearDiscriminantAnalysis())\n",
    "frontal_mask = nib.load(\"/mnt/nfs/lss/lss_kahwang_hpc/ROIs/MNI_frontal.nii.gz\")\n",
    "\n",
    "img = nib.load(\n",
    "    THAL_HI_DIR + \"fmriprep/sub-10001/func/sub-10001_task-ThalHi_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\")\n",
    "imgs = nib.Nifti1Image(subject_lss_data.data,\n",
    "                        affine=img.affine, header=img.header)\n",
    "\n",
    "# resample imgs and mask to 3x3x3\n",
    "template = load_mni152_template(resolution=3)\n",
    "frontal_mask = resample_to_img(frontal_mask, template, interpolation='nearest')\n",
    "resampled_imgs = resample_to_img(imgs, template)\n",
    "\n",
    "function = decode_cues\n",
    "additional_args = [subject_lss_data.trial_df.Cue.to_numpy(), clf, CUES, subject_lss_data.trial_df.Run.to_numpy()]\n",
    "sl_obj = searchlight.SearchLight(frontal_mask, function, additional_args, verbose=1, radius=10.0, n_jobs=4)\n",
    "sl_obj.run(resampled_imgs)\n",
    "print(sl_obj.output)\n",
    "pickle.dump(sl_obj, open(os.path.join(dir_tree.deconvolve_dir, \"searchlight_lda.p\", \"wb\")), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output will be list of whatever your function returns with a length equal to number of voxels in mask. It should then be easy to use the mask to transform data back to 3D brain space.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python383jvsc74a57bd0b945bfa426ab19dcb1b57a95042a567490cf91a191c6db7383bb4e52050ebd91"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "b945bfa426ab19dcb1b57a95042a567490cf91a191c6db7383bb4e52050ebd91"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}