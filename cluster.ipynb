{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Perform the NBS for populations X and Y for a t-statistic threshold of alpha.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : NxMxP np.ndarray, NXP np.ndarray, or 4D Nifti1Image - VOXELSxP\n",
    "        matrix representing the first population with P subjects. must include masker if data is NXP\n",
    "    y : NxMxQ np.ndarray, NXQ np.ndarray, or 4D Nifti1Image - VOXELSxQ\n",
    "        matrix representing the second population with Q subjects. Q need not\n",
    "        equal P unless paired is set to true.\n",
    "    thresh : float\n",
    "        minimum t-value used as threshold\n",
    "    k : int\n",
    "        number of permutations used to estimate the empirical null\n",
    "        distribution\n",
    "    tail : {'left', 'right', 'both'}\n",
    "        enables specification of particular alternative hypothesis\n",
    "        'left' : mean population of X < mean population of Y\n",
    "        'right' : mean population of Y < mean population of X\n",
    "        'both' : means are unequal (default)\n",
    "    paired : bool\n",
    "        use paired sample t-test instead of population t-test. requires both\n",
    "        subject populations to have equal N. default value = False\n",
    "    verbose : bool\n",
    "        print some extra information each iteration. defaults value = False\n",
    "    seed : hashable, optional\n",
    "        If None (default), use the np.random's global random state to generate random numbers.\n",
    "        Otherwise, use a new np.random.RandomState instance seeded with the given value.\n",
    "    Returns\n",
    "    -------\n",
    "    pval : Cx1 np.ndarray\n",
    "        A vector of corrected p-values for each component of the networks\n",
    "        identified. If at least one p-value is less than alpha, the omnibus\n",
    "        null hypothesis can be rejected at alpha significance. The null\n",
    "        hypothesis is that the value of the connectivity from each edge has\n",
    "        equal mean across the two populations.\n",
    "    adj : IxIxC np.ndarray\n",
    "        an adjacency matrix identifying the edges comprising each component.\n",
    "        edges are assigned indexed values.\n",
    "    null : Kx1 np.ndarray\n",
    "        A vector of K sampled from the null distribution of maximal component\n",
    "        size.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, the cluster takes two different conditions, runs t-tests between two conditions & thresholds to create suprathersholded matrix, finds components that are clustered together in matrix, generates a null model from max cluster size of k permutations, and compares null model and components to generate p-values\n",
    "\n",
    "Conditions can be 2d (voxels x subjects), 3d (n x m x subjects, usually fc connectivity), and 4d nifti image, (x, y, z, subjects)\n",
    "\n",
    "Xitong knows this stuff too so you can ask her for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "from thalpy import base, masks\n",
    "import numpy as np\n",
    "from neuro_cluster import cluster\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "dir_tree = base.DirectoryTree('/data/backed_up/shared/xitchen_WM')\n",
    "subjects = base.get_subjects(dir_tree.deconvolve_dir, dir_tree)\n",
    "\n",
    "tasks = ['body-others', 'faces-others', 'places-others', 'tools-others', '2bk-0bk', '0bk', '2bk',\n",
    "         '2bk_body-0bk_body', '2bk_faces-0bk_faces', '2bk_places-0bk_places', '2bk_tools-0bk_tools']\n",
    "\n",
    "thal_masker = masks.binary_masker(masks.MOREL_PATH)\n",
    "thal_masker.fit(nib.load(\n",
    "    \"/data/backed_up/shared/xitchen_WM/3dDeconvolve/sub-100206/100206_FIRmodel_errts_REML+tlrc.nii.gz\"))\n",
    "\n",
    "betas = np.load(\"thal_betas.npy\")\n",
    "print(betas.shape)\n",
    "task1 = betas[:, 0, :]\n",
    "task2 = betas[:, 4, :]\n",
    "comps, pvals, adj, null_arr, sz_comps = cluster.run(task1, task2, masker=thal_masker,\n",
    "                                                    thresh=2.583, k=1, tail='both', paired=True)\n",
    "\n",
    "print(comps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python383jvsc74a57bd0b945bfa426ab19dcb1b57a95042a567490cf91a191c6db7383bb4e52050ebd91"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "5360a8a1268f096c13c8df890fc4a16c0167eeb01ca5fdbdc6c7f6464813bd70"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}